{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf354c14-436f-49fc-8707-ec5c263fed48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools as it\n",
    "from scipy.spatial.distance import cosine\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651112f9-19f1-4453-be14-58181d9d2ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "all_ratings = pd.read_csv('/Users/irenebonafonte/Downloads/data_for_model/ratings.csv')\n",
    "all_ratings.drop('rating_date', axis=1, inplace=True) \n",
    "all_ratings.shape, all_ratings.userId.nunique(), all_ratings.movieId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f509b060-fe57-4d1f-84c4-5e024b88e96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only movies used in CF\n",
    "content_ids = pd.read_csv('content_based_index.txt')\n",
    "content_ids = content_ids['movieId'].unique()\n",
    "all_ratings = all_ratings[all_ratings.movieId.isin(content_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a02b1302-4ddc-4121-b89d-424257f00d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "    def __init__(self, DataFrame, sim_method='CosineSim', scale_rate=True, balance_ncommon=True, N='all'):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        \n",
    "        if sim_method == 'CosineSim':\n",
    "            self.sim_method=cosine\n",
    "            \n",
    "        elif sim_method == 'SVDsim':\n",
    "            self.sim_method='svd_similarity'\n",
    "            \n",
    "        elif sim_method == 'pearsonCor':\n",
    "            self.sim_method=pearsonr\n",
    "            \n",
    "        self.df=DataFrame\n",
    "        self.sim = {}\n",
    "        self.scale_rate = scale_rate\n",
    "        self.balance_ncommon = balance_ncommon\n",
    "        \n",
    "        # Select the number of similar items to be taken into account when\n",
    "        # predicting ratings. By default, all items are used.        \n",
    "        self.N = N\n",
    "        \n",
    "        return\n",
    "            \n",
    "    def similarity(self, items):\n",
    "        # Find users that have rated both items\n",
    "        users = np.intersect1d(self.df_np[self.df_np[:,1] == items[0],0], \n",
    "                               self.df_np[self.df_np[:,1] == items[1],0])\n",
    "\n",
    "        if len(users) >= self.min_common:\n",
    "            user_bools = np.isin(self.df_np[:,0], users, assume_unique=False)\n",
    "\n",
    "            # Compute similarity\n",
    "            sim = self.sim_method(self.df_np[(user_bools & (self.df_np[:,1] == items[0])),2],\n",
    "                                  self.df_np[(user_bools & (self.df_np[:,1] == items[1])),2])\n",
    "            \n",
    "            if self.sim_method == cosine:\n",
    "                 sim = 1 - sim\n",
    "                    \n",
    "            elif self.sim_method == pearsonr:\n",
    "                sim = sim[0]\n",
    "\n",
    "            # Balance the similarity score by considering the number of users taken into account\n",
    "            if self.balance_ncommon:\n",
    "                sim = sim * min(50,len(users))/50\n",
    "            \n",
    "            # we do not want negative similarities (would result in negative ratings)\n",
    "            if sim <= 0:\n",
    "                sim = np.nan\n",
    "            \n",
    "        else:\n",
    "            sim = np.nan\n",
    "            \n",
    "        return sim \n",
    "    \n",
    "    def svd_similarity(self):  \n",
    "        reader = Reader(rating_scale=(0, 5))\n",
    "        trainset = Dataset.load_from_df(self.df, reader)\n",
    "        trainset = trainset.build_full_trainset()\n",
    "        svd = SVD(verbose=True, biased=False, n_epochs=20)\n",
    "        svd.fit(trainset)\n",
    "        latent_factors = svd.qi\n",
    "        self.sim_mat = np.corrcoef(latent_factors)\n",
    "        \n",
    "        # Sort IDs\n",
    "        order = np.argsort(self.allItems)\n",
    "        self.sim_mat = self.sim_mat[order,:]\n",
    "        self.sim_mat = self.sim_mat[:,order]\n",
    "        self.allItems_sorted = self.allItems[order]\n",
    "        \n",
    "        return\n",
    "        \n",
    "    def fit(self, min_common=2):        \n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for items \"\"\"\n",
    "        \n",
    "        # Minimum of common users required for the similarity to be computed\n",
    "        self.min_common = min_common \n",
    "        self.allItems=self.df['movieId'].unique()\n",
    "        \n",
    "        if self.sim_method == 'svd_similarity':\n",
    "            self.df_np = self.df.to_numpy()\n",
    "            self.svd_similarity()\n",
    "            \n",
    "            return\n",
    "\n",
    "        if self.scale_rate:\n",
    "            # For the computation of the adjusted cosine similarity\n",
    "            # we substract the user mean rating from the film ratings \n",
    "            # so that it does not influence the calculation of similarities.\n",
    "\n",
    "            means = self.df.groupby('userId')[['rating']].mean()\n",
    "            self.df['userMean'] = means.loc[self.df['userId']].values\n",
    "            self.df['scaledRating'] = self.df['rating'] - self.df['userMean']\n",
    "            self.df.drop('userMean', axis=1, inplace=True)\n",
    "            # Position similarity metric in third column\n",
    "            self.df = self.df[['userId','movieId','scaledRating','rating']] \n",
    "        \n",
    "        self.df_np = self.df.to_numpy()\n",
    "        self.sim_mat = np.array(list(it.combinations(self.allItems,2)))\n",
    "        self.sim_mat = np.concatenate((self.sim_mat, np.empty((self.sim_mat.shape[0],1))), axis=1)\n",
    "\n",
    "        self.sim_mat[:,2] = np.apply_along_axis(self.similarity, axis=1, arr=self.sim_mat[:,0:2])\n",
    "        self.sim_mat = self.sim_mat[~np.isnan(self.sim_mat[:,2]),:]\n",
    "        \n",
    "        # Back to normal column order\n",
    "        if self.scale_rate:\n",
    "            self.df = self.df.drop(['scaledRating'], axis=1)\n",
    "            self.df_np = self.df.to_numpy()\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def svd_predict(self, user_id, movie_id, user_ratings):\n",
    "        # Get similarity between movie to predict (row) and rated movies (columns)\n",
    "        movie_sim = self.sim_mat[(self.allItems_sorted == movie_id), np.isin(self.allItems_sorted,user_ratings[:,0])].copy() \n",
    "        rating = np.sum((user_ratings[:,1] * movie_sim)) / np.sum(movie_sim)\n",
    "        \n",
    "        return min(rating, 5)\n",
    "        \n",
    "    def predict(self, user_id, movie_id):\n",
    "        # user_u ratings\n",
    "        user_ratings = self.df_np[self.df_np[:,0] == user_id,1:3]\n",
    "        user_ratings = user_ratings[np.argsort(user_ratings[:,0]), :] # sort by movie_id\n",
    "        \n",
    "        if self.sim_method == 'svd_similarity':\n",
    "            rating = self.svd_predict(user_id, movie_id, user_ratings)\n",
    "            return rating\n",
    "\n",
    "        # movie_i similarities\n",
    "        movie_sim = self.sim_mat[(self.sim_mat[:,0] == movie_id) | (self.sim_mat[:,1] == movie_id), :]\n",
    "        # put movie_j in first column and remove second column\n",
    "        movie_sim[movie_sim[:,1] == movie_id,1] = movie_sim[movie_sim[:,1] == movie_id,0]\n",
    "        \n",
    "        # Select top N most similar items to do the prediction\n",
    "        if self.N != 'all':\n",
    "            N = min(movie_sim.shape[0], self.N)\n",
    "            movie_sim = movie_sim[np.argsort(-movie_sim[:,2]), ] # sort by similarity\n",
    "            movie_sim = movie_sim[0:N, :] # Keep top N\n",
    "            \n",
    "        movie_sim = movie_sim[np.argsort(movie_sim[:,1]), 1:3] # sort by movie_id\n",
    "\n",
    "        # subset to movies with user_u rating and similarity to movie_i\n",
    "        to_weight = np.intersect1d(user_ratings[:,0], movie_sim[:,0])\n",
    "        if len(to_weight) > 0:\n",
    "            user_ratings = user_ratings[np.isin(user_ratings[:,0], to_weight),:]\n",
    "            movie_sim = movie_sim[np.isin(movie_sim[:,0], to_weight),:]\n",
    "\n",
    "            rating = np.sum((user_ratings[:,1] * movie_sim[:,1])) / np.sum(movie_sim[:,1])\n",
    "            \n",
    "        else:\n",
    "            return np.mean(user_ratings[:,1]) # Assign user mean\n",
    "\n",
    "        return min(rating, 5) # Limit to 5\n",
    "\n",
    "    def rmse_evaluate(self, data_test):\n",
    "        \"\"\" RMSE-based predictive performance evaluation. \"\"\"\n",
    "        \n",
    "        # Exclude from testing users for which we do not have any ratings\n",
    "        data_test = data_test.loc[data_test.userId.isin(self.df.userId.unique()),:]\n",
    "        print('Evaluating performance with n='+str(data_test.userId.nunique())+' users.')\n",
    "        \n",
    "        to_estimate = data_test[['userId','movieId']].to_numpy()\n",
    "        y = data_test[['rating']].values\n",
    "        \n",
    "        # Predict rating for each user-movie pair\n",
    "        y_hat = np.apply_along_axis(lambda x: self.predict(x[0], x[1]), axis=1, arr=to_estimate)\n",
    "        \n",
    "        rmse = np.sqrt(np.mean(np.power(y_hat - y, 2)))\n",
    "        return rmse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaf4019-e946-415b-aa15-cfea80d9b1af",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c760aec9-8a77-4805-a3b4-2155cdb058ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n"
     ]
    }
   ],
   "source": [
    "recomend = CollaborativeFiltering(all_ratings, sim_method='SVDsim')\n",
    "recomend.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc978a25-2e90-4dc1-bbf9-5b315886e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = recomend.sim_mat\n",
    "model_movie_index = recomend.allItems_sorted.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87475b0-7174-4b24-abc6-e8f38886bd11",
   "metadata": {},
   "source": [
    "# Upload to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47c761e-4ec5-4417-abee-69ccb8e95ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dir_data_raw': '../data/raw', 'dir_data_input': '../data/input', 'db_url': 'cluster0.egjki.mongodb.net', 'db_name': 'gmam', 'db_user': 'getmeamovie_rw'}\n"
     ]
    }
   ],
   "source": [
    "# Read configuration file\n",
    "with open('config_prod.json', 'r') as fp:\n",
    "    config = json.load(fp)\n",
    "print(config)\n",
    "\n",
    "\n",
    "def encode_matrix(matrix, id_list, num_digits=2):\n",
    "    '''Encode similarity matrix as list of strings\n",
    "       Every string will correspond to a row of the matrix, with each value coded as a fixed number of digits\n",
    "       Input:\n",
    "           - matrix: 2-dimensional array of float values between 0 and 1\n",
    "           - id_list: list of id values\n",
    "           - num_digits: number of digits for each value (default 2)\n",
    "       Returns:\n",
    "           - matrix_out: formatted matrix (list of strings)\n",
    "    '''\n",
    "    if not (matrix.shape[0] == matrix.shape[1] and matrix.shape[0] == len(id_list)):\n",
    "        raise ValueError('[encode_matrix] The matrix dimensions must match with the size of the id_list')\n",
    "        \n",
    "    matrix_out = []\n",
    "    d_movies = []\n",
    "    for i in range(len(matrix)):\n",
    "        row_string=''\n",
    "        for j in range(len(matrix)):\n",
    "            x = matrix[i,j]\n",
    "            if x<0 or x>1:\n",
    "                raise ValueError('[encode_matrix] The matrix values must be between 0 and 1 - error in value [{},{}] '.format(i,j))\n",
    "            x_int = int(x*10**num_digits)  # Convert into n-digit integer\n",
    "            if x_int==10**num_digits:  # Values of 1 will be converted to 0.99\n",
    "                x_int -= 1\n",
    "            row_string = row_string + format(x_int, '0'+str(num_digits)+'d')\n",
    "        matrix_out.append({'movieId':id_list[i], 'similarities':row_string})\n",
    "    return matrix_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a69993a-523e-48f7-a620-ae24e9e91488",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity[similarity < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05312c5e-d2ab-46d7-a17b-7fff2b663870",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_sim_matrix = encode_matrix(similarity, model_movie_index, num_digits=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea9fad8b-4950-4f7a-8a8b-d87e8a990dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing connection\n",
      "Connected successfully to MongoDB\n"
     ]
    }
   ],
   "source": [
    "# Connect to MongoDB\n",
    "\n",
    "db_url = config['db_url']\n",
    "db_name = config['db_name']\n",
    "db_user = config['db_user']\n",
    "\n",
    "import pymongo\n",
    "import ssl\n",
    "try:\n",
    "    # Close previous connection\n",
    "    if 'conn' in globals():\n",
    "        conn.close()\n",
    "        print(\"Closing connection\")\n",
    "    \n",
    "    # Read from db_credentials.txt password required to connect to MongoDB.\n",
    "    with open(\"db_credentials.txt\", 'r') as f:\n",
    "        [db_password] = f.read().splitlines()\n",
    "    \n",
    "    # Connect\n",
    "    conn=pymongo.MongoClient(\"mongodb+srv://{}:{}@{}\".format(db_user, db_password, db_url), ssl_cert_reqs=ssl.CERT_NONE)\n",
    "    print (\"Connected successfully to MongoDB\")\n",
    "    \n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e) \n",
    "    \n",
    "# Open database and collection\n",
    "db = conn[db_name]\n",
    "col_similarity = db['similarity_CF']\n",
    "\n",
    "col_similarity.delete_many({})  # Delete previous data in the collection\n",
    "\n",
    "col_similarity.insert_many(f_sim_matrix)  # Insert formatted similarity matrix\n",
    "\n",
    "# Close connection to MongoDB\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dac81aad-77a3-4881-bf88-27a87823a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing connection\n",
      "Connected successfully to MongoDB\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Close previous connection\n",
    "    if 'conn' in globals():\n",
    "        conn.close()\n",
    "        print(\"Closing connection\")\n",
    "    \n",
    "    # Read from db_credentials.txt password required to connect to MongoDB.\n",
    "    with open(\"db_credentials.txt\", 'r') as f:\n",
    "        [db_password] = f.read().splitlines()\n",
    "    \n",
    "    # Connect\n",
    "    conn=pymongo.MongoClient(\"mongodb+srv://{}:{}@{}\".format(db_user, db_password, db_url), ssl_cert_reqs=ssl.CERT_NONE)\n",
    "    print (\"Connected successfully to MongoDB\")\n",
    "    \n",
    "except pymongo.errors.ConnectionFailure as e:\n",
    "    print (\"Could not connect to MongoDB: %s\" % e) \n",
    "    \n",
    "db = conn[db_name]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db284959-bb7b-41d4-a567-e8b825284db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['similarity', 'similarity_CF', 'movies', 'similarity_content_based']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8f1f60f-8dbe-41af-a892-28b75920031e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['similarity_CF', 'movies', 'similarity_content_based']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.drop_collection(\"similarity\")\n",
    "db.list_collection_names()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
