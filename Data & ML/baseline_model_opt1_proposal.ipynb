{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c169537d",
   "metadata": {},
   "source": [
    "# General overview on Recommendation systems for movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c2dca0",
   "metadata": {},
   "source": [
    "There are basically three types of recommender systems:\n",
    "\n",
    "* **Demographic Filtering**: offer generalized recommendations to every user, based on movie popularity and/or genre. The System recommends the same movies to users with similar demographic features. Since each user is different , this approach is considered to be too simple. The basic idea behind this system is that movies that are more popular and critically acclaimed will have a higher probability of being liked by the average audience.\n",
    "\n",
    "* **Content Based Filtering**: suggest similar items based on a particular item. This system uses item metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. The general idea behind these recommender systems is that if a person liked a particular item, he or she will also like an item that is similar to it.\n",
    "\n",
    "* **Collaborative Filtering**: this system matches persons with similar interests and provides recommendations based on this matching. Collaborative filters do not require item metadata like its content-based counterparts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be473683",
   "metadata": {},
   "source": [
    "# Baseline model proposal\n",
    "\n",
    "For the baseline model, we have to consider that our data mainly consists on ratings. There are only two movie features: the title and the genre. This type of data suggests the use of **collaborative filtering**. The recommended movies are based on the ratings given by other users (that are similar to the user of interest). \n",
    "\n",
    "Two main types of methods of collaborative filtering exist:\n",
    "\n",
    "* **Neighbourhood-based methods**: the similarity between items or between users is computed based on their ratings. Ratings are predicted based on the rating given by the most simlar users. The problem with using user-similarity based methods is that the user-user similarity matrix needs to be re-computed when a new user is added, which means that all data needs to be accessed when running the application. Item-based methods may be better because the similarity matrix is already pre-computedm and is more stable.\n",
    "\n",
    "* **(Latent Factor) Model-based methods**: Methods that explain the rating by characterizing users and items using latent factor analysis. Pairwise similarities can then be computed based on this low level representations. This solves the problem of having to work with large sparse matrices.\n",
    "\n",
    "For this first sprint, we will work with item similarity methods, which seem to be more adequate and directly appliable for our specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faada9bb",
   "metadata": {},
   "source": [
    "## Item based neighbourhood methods\n",
    "\n",
    "Item similarity measures are more stable and static than user similarities. This is good, because we would like to compute the similarity matrix only once. To use this method we need to decide:\n",
    "\n",
    "* Which simiarlity measure are we going to use.\n",
    "* How are we going to make the predictions.\n",
    "* Which metric will we use to evaluate the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31785e0",
   "metadata": {},
   "source": [
    "### Similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e105233",
   "metadata": {},
   "source": [
    "To compute similarity, we need to pick, for each item, the users that have rated both items. Using these users, we will compute the similarity between both items, using measures such as Euclidean distance, Pearson correlation, corrected Pearson correlation, Spearman correlation or cosine distance. In practice, cosine similarity has shown to work well for item-item similarity. However, we should use an adjusted version of this measure (the Adjusted Cosine Similarity), in which we take into account the differences in the rating scales used by each user, by substracting the user average from the actual ratings. Another option is to train a model to learn the similarity weights that lead to better predictions.\n",
    "\n",
    "It is a good idea to weight the similarity score by the number of users that two items have in common. This will avoid giving a high similarity score based on only a few ratings, which would not be reliable (**significance weighting**).\n",
    "\n",
    "$sim(u,v) = sim(u,v) \\times \\frac{min(50|U_u \\cap U_v)}{50}$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c090e7",
   "metadata": {},
   "source": [
    "### Prediction method\n",
    "\n",
    "We will define the predicted rating for one user as the weighted average of the ratings that this particular user has given to similar items. This could be done by taking into account only the top-k most similar items, which would also reduce the cost of the computations to be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f97bb",
   "metadata": {},
   "source": [
    "### Performance metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c2fe9f",
   "metadata": {},
   "source": [
    "For this baseline model, we will evaluate performance using the Root Mean Squared Error (RMSE), which is typically used for numeric predictions. However, we should take into account that our true interest is not to predict the actual rating, but to predict the movies that the user will enjoy the most. Therefore, we are interested in the ranking (not rating) of its top movies. There are different metrics that let us directly evaluate this: \n",
    "\n",
    "* Measures that foccus on the **Top-K recommendations**: precision@K (numer of items user likes among the top K/K), recall@K (numer of items user likes among the top K/total number of items that the user likes), Mean Average Precision @K (MAP@K - computes the precision at the position of the top K item in the ranked list), Normalized Discounted Cumulative Gain (NDCG). However, these functions are not differentiable, so it is difficult to use them to optimize a ML model. We could use it, however, not for optimization but to get a better idea of model performance.\n",
    "\n",
    "* **Learning to rank** (LTR): refers to the use of optimization techniques that directly minimize the error in the rank-order. Pointwise (predict absolute ranking position; RMSE), pairwise (predict, for two items, which one does the user prefer; AUC) or listwise (predict the ranking of a list of items; cross entropy).\n",
    "\n",
    "For the baseline model that we have proposed, there is no optimization to be done, so LTR has no applicability. We could explore this in later stages of the project. However, top-k recommendation metrics should be considered when evalutating model performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
